{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root = \"C:\\\\Users\\\\saman\\\\OneDrive\\\\Documents\\\\GitHub\\\\Eyelid-Modeling\\\\\"\n",
    "sys.path.append(root)\n",
    "\n",
    "from utils.experiment_manager import Experiment\n",
    "from models.EMG_RNN import EMG_RNN_Wrapper\n",
    "from utils.data_management import Mat2TVT\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Reorganization** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_bool = np.asarray([True, True, False, True, True, False, False, False])\n",
    "electrode_list = ['u1', 'u2', 'u3', 'u4', 't2']\n",
    "marker_list = ['u1', 'u2', 'u3', 'u4', 'u5']\n",
    "filepath = root + 'eyeliddata.mat'\n",
    "\n",
    "train = 0.7\n",
    "val = 0.2\n",
    "test = 0.1\n",
    "\n",
    "reorganizer = Mat2TVT(eye_bool, electrode_list, marker_list, filepath)\n",
    "_, _, identifier = reorganizer.load_data()\n",
    "X, y = reorganizer.DMVC_norm()\n",
    "TVT_dict = reorganizer.TVT_split(train, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    't_win': np.arange(10,51,1, dtype = float),\n",
    "    't_stride': np.arange(10, 51, 1, dtype = float),\n",
    "    't_lookahead': np.arange(50, 101, 1, dtype = float),\n",
    "    'win_mode': ['win_fft', 'win_rect'],\n",
    "    'p_transform': np.linspace(0, 1, 100, dtype = float),\n",
    "    'sigma': np.linspace(0, 5, 100, dtype = float),\n",
    "    'p_mask': np.linspace(0, 0.5, 100, dtype = float),\n",
    "    'batch_size': [4, 8, 16, 32, 64, 128],\n",
    "    'learning_rate': np.linspace(1e-3, 1e-8, 500, dtype = float),\n",
    "    'dropout': np.linspace(0, 1, 100, dtype = float),\n",
    "    'RNN_hdim': [4, 8, 16, 32, 64, 128],\n",
    "    'RNN_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "experiment = Experiment()\n",
    "model = EMG_RNN_Wrapper()\n",
    "best_params = experiment(params, TVT_dict, model, n_trials = 300, epochs = 100, patience = 100) \n",
    "\n",
    "print(\"Best Params:\\n_________________________________________________________________________________________________________\")\n",
    "for key, value in best_params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training Model with Best Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = experiment.run_experiment(best_params, TVT_dict, model, epochs = 1000, patience = 200)\n",
    "\n",
    "'''\n",
    "Saving Model, Training Metrics, and Best Params\n",
    "'''\n",
    "with open(\"training_metrics.pickle\", \"wb\") as file:\n",
    "    pickle.dump(metrics, file)\n",
    "with open(\"best_params.pickle\", \"wb\") as file:\n",
    "    pickle.dump(best_params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plotting Loss Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['Training Loss'], label = 'Training Loss', marker = '.')\n",
    "plt.plot(metrics['Validation Loss'], label = 'Validation Loss', marker = '.')\n",
    "plt.yscale('log')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(metrics['Training Avg Marker Error'], label = 'Training Error', marker = '.')\n",
    "plt.plot(metrics['Validation Avg Marker Error'], label = 'Validation Error', marker = '.')\n",
    "plt.yscale('log')\n",
    "plt.title('Average Marker Error vs. Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Marker Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(metrics['Training Max Marker Error'], label = 'Training Error', marker = '.')\n",
    "plt.plot(metrics['Validation Max Marker Error'], label = 'Validation Error', marker = '.')\n",
    "plt.yscale('log')\n",
    "plt.title('Max Marker Error vs. Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Max Marker Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
