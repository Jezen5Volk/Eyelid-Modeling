{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "root = \"C:\\\\Users\\\\saman\\\\OneDrive\\\\Documents\\\\GitHub\\\\Eyelid-Modeling\\\\\" #laptop path\n",
    "#root = \"C:\\\\Users\\\\Samantha\\\\Documents\\\\GitHub\\\\Eyelid-Modeling\\\\\" #desktop path\n",
    "sys.path.append(root)\n",
    "\n",
    "from utils.experiment_manager import Experiment\n",
    "from models.EMG_RNN_CNN import EMG_RNN_CNN_Wrapper\n",
    "from utils.data_management import Mat2TVT\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Reorganization** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_bool = np.asarray([True, True, False, True, True, False, False, False])\n",
    "electrode_list = ['u1', 'u2', 'u3', 'u4', 't2']\n",
    "marker_list = ['u1', 'u2', 'u3', 'u4', 'u5']\n",
    "filepath = root + 'eyeliddata.mat'\n",
    "\n",
    "train = 0.7\n",
    "val = 0.2\n",
    "test = 0.1\n",
    "\n",
    "reorganizer = Mat2TVT(eye_bool, electrode_list, marker_list, filepath)\n",
    "_, _, identifier = reorganizer.load_data()\n",
    "X, y = reorganizer.DMVC_norm()\n",
    "TVT_dict = reorganizer.TVT_split(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-14 04:03:14,857] A new study created in memory with name: no-name-21b9569d-7db6-4995-a7ee-aa3ac7679a4a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-14 04:03:41,938] Trial 0 finished with value: 118.41309356689453 and parameters: {'t_win': np.float64(41.0), 't_stride': np.float64(11.0), 't_lookahead': np.float64(100.0), 'win_mode': 'win_rect', 'p_transform': np.float64(0.7373737373737375), 'sigma': np.float64(2.4242424242424243), 'p_mask': np.float64(0.13131313131313133), 'batch_size': 8, 'learning_rate': np.float64(0.00016233302605210412), 'dropout': np.float64(0.29292929292929293), 'RNN_hdim': 4, 'RNN_depth': 10, 'CNN_kernel': 5}. Best is trial 0 with value: 118.41309356689453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: \n",
      " Max Marker Error: 3650.2%, Avg Marker Error: 118.4%, Avg loss: 1.071774 \n",
      "\n",
      "Done!\n",
      "Best Params:\n",
      "_________________________________________________________________________________________________________\n",
      "    t_win: 41.0\n",
      "    t_stride: 11.0\n",
      "    t_lookahead: 100.0\n",
      "    win_mode: win_rect\n",
      "    p_transform: 0.7373737373737375\n",
      "    sigma: 2.4242424242424243\n",
      "    p_mask: 0.13131313131313133\n",
      "    batch_size: 8\n",
      "    learning_rate: 0.00016233302605210412\n",
      "    dropout: 0.29292929292929293\n",
      "    RNN_hdim: 4\n",
      "    RNN_depth: 10\n",
      "    CNN_kernel: 5\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    't_win': np.arange(10,51,1, dtype = float),\n",
    "    't_stride': np.arange(10, 51, 1, dtype = float),\n",
    "    't_lookahead': np.arange(50, 101, 1, dtype = float),\n",
    "    'win_mode': ['win_fft', 'win_rect'],\n",
    "    'p_transform': np.linspace(0, 1, 100, dtype = float),\n",
    "    'sigma': np.linspace(0, 5, 100, dtype = float),\n",
    "    'p_mask': np.linspace(0, 0.5, 100, dtype = float),\n",
    "    'batch_size': [4, 8, 16, 32, 64, 128],\n",
    "    'learning_rate': np.linspace(1e-3, 1e-8, 500, dtype = float),\n",
    "    'dropout': np.linspace(0, 1, 100, dtype = float),\n",
    "    'RNN_hdim': [4, 8, 16, 32, 64, 128],\n",
    "    'RNN_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'CNN_kernel': [3, 5]\n",
    "}\n",
    "\n",
    "experiment = Experiment()\n",
    "model = EMG_RNN_CNN_Wrapper()\n",
    "gcollect = True\n",
    "best_params = experiment(params, TVT_dict, model, n_trials = 100, epochs = 100, patience = 25, gcollect) \n",
    "\n",
    "print(\"Best Params:\\n_________________________________________________________________________________________________________\")\n",
    "for key, value in best_params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training Model with Best Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = experiment.run_experiment(best_params, TVT_dict, model, epochs = 1000, patience = 200)\n",
    "\n",
    "'''\n",
    "Saving Model, Training Metrics, and Best Params\n",
    "'''\n",
    "with open(\"training_metrics.pickle\", \"wb\") as file:\n",
    "    pickle.dump(metrics, file)\n",
    "with open(\"best_params.pickle\", \"wb\") as file:\n",
    "    pickle.dump(best_params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plotting Loss Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['Training Loss'], label = 'Training Loss', marker = '.')\n",
    "plt.plot(metrics['Validation Loss'], label = 'Validation Loss', marker = '.')\n",
    "plt.yscale('log')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(metrics['Training Avg Marker Error'], label = 'Training Error', marker = '.')\n",
    "plt.plot(metrics['Validation Avg Marker Error'], label = 'Validation Error', marker = '.')\n",
    "plt.yscale('log')\n",
    "plt.title('Average Marker Error vs. Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Marker Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(metrics['Training Max Marker Error'], label = 'Training Error', marker = '.')\n",
    "plt.plot(metrics['Validation Max Marker Error'], label = 'Validation Error', marker = '.')\n",
    "plt.yscale('log')\n",
    "plt.title('Max Marker Error vs. Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Max Marker Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
