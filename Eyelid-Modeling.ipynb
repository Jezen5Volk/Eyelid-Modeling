{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "mat = scipy.io.loadmat('eyeliddata.mat', simplify_cells = True)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Reorganization** <br>\n",
    "Reorganizing provided matlab file and interpolating over recoverable NaN labels\n",
    "\n",
    "For a single trial, \n",
    "\n",
    "- Marker kinematics are provided at 400 Hz, shape (300, 3) --> 0.75 s\n",
    "- EMG information is provided at 6103.5 Hz, shape (4564,) --> 0.7478 s\n",
    "\n",
    "Marker and EMG data are time-synced. Blinking starts at around 0.25 seconds, which corresponds to point 100 for the kinematics data and point 1525 in the EMG data\n",
    "\n",
    "Since only electrodes u1, u2, u3, u4, and t2 were used in common across all participants, our input to the model (without spectral preprocessing) will be of shape (4564, N, 5). Since only markerset x1, x2, A, B, C, D, E were used in common across all participants, our labels will be of shape (N, 7, 300, 3). In other words, $x \\in R^{T_{\\mathrm{in}}\\times N \\times C_{\\mathrm{in}}}$, where $T_{\\mathrm{in}}$ is the number of timesteps (4564, in this case), N is the batch size, and $C_{\\mathrm{in}}$ is the number of channels (5, in this case), while $y \\in R^{T_{\\mathrm{out}}\\times 3\\times N \\times C_{\\mathrm{out}}}$, where where $T_{\\mathrm{out}}$ is the number of timesteps (300 x 3, in this case), N is the batch size, and $C_{\\mathrm{out}}$ is the number of channels (7, in this case).\n",
    "\n",
    "To reorganize the data for train-test-val splits, the Nth data/label pair should contain the timeseries for emg electrodes u1, u2, u3, u4, t2/the timeseries for markerset x1, x2, A, B, C, D, E. In addition to this, a static identification label is generated which contains an identifying string combining the subject, blink type, and trial number (ie: 'sub1_spon#23'), a boolean hyperparameter indicating eye side (True = Right Eye, False = Left Eye); and a flag to identify whether the trial contains NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (4564, 986, 5)\n",
      "Label Shape:  (300, 3, 986, 7)\n",
      "Identifier Shape:  (986, 3)\n",
      "Shapes Validated!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Reorganize Data\n",
    "'''\n",
    "eye_bool = np.asarray([True, True, False, True, True, False, False, False])\n",
    "electrode_list = ['u1', 'u2', 'u3', 'u4', 't2']\n",
    "marker_list = ['x1', 'x2', 'u1', 'u2', 'u3', 'u4', 'u5']\n",
    "\n",
    "\n",
    "#Collect Data\n",
    "data = np.zeros((4564, 1, 5))\n",
    "for blink_key in mat['ForSamantha']['emg_with_notchfilter']:\n",
    "    for sub_key in mat['ForSamantha']['emg_with_notchfilter'][blink_key]:\n",
    "        trial = []\n",
    "        for electrode_key in electrode_list:\n",
    "            trial.append(mat['ForSamantha']['emg_with_notchfilter'][blink_key][sub_key][electrode_key])\n",
    "        trial = np.dstack(trial) #reshape to (4564, T, 5) where T is number of trials\n",
    "        data = np.hstack((data, trial)) #stack all trials along 1st axis --> (4564, N, 5)\n",
    "\n",
    "\n",
    "#Collect Label/Identifier\n",
    "identifier = []\n",
    "label = np.zeros((300, 3, 1, 7))\n",
    "for blink_key in mat['ForSamantha']['kinem']:\n",
    "    for sub_key in mat['ForSamantha']['kinem'][blink_key]:\n",
    "        trial = []\n",
    "        for marker_key in marker_list:\n",
    "            trial.append(mat['ForSamantha']['kinem'][blink_key][sub_key][marker_key])\n",
    "        trial = np.stack(trial, axis = -1) #reshape to (300, 3, T, 7) where T is number of trials\n",
    "\n",
    "        #Identifier markers for trials with incomplete data\n",
    "        throwaway = False\n",
    "        if trial.shape[0] != 300:\n",
    "            throwaway = True\n",
    "\n",
    "        #If not discarding a trial, stack it's label\n",
    "        if not(throwaway):\n",
    "            label = np.dstack((label, trial)) #stack all trials along 2nd axis --> (300, 3, N, 7)\n",
    "        \n",
    "        #Generate ID for each trial\n",
    "        for num in range(trial.shape[2]):\n",
    "            id_string = sub_key + '_' + blink_key + '#' + str(num + 1) \n",
    "            id_eye = eye_bool[int(sub_key.split('b')[1]) - 1]\n",
    "            identifier.append((id_string, id_eye, False, throwaway))\n",
    "\n",
    "\n",
    "#Remove placeholder\n",
    "X = data[:, 1:, :] \n",
    "y = label[:, :, 1:, :]\n",
    "identifier = np.asarray(identifier)\n",
    "\n",
    "\n",
    "#Remove throwaway trials from data/identifier\n",
    "idx = np.where(identifier[:,3] == 'True')\n",
    "X = np.delete(X, idx, axis = 1)\n",
    "identifier = np.delete(identifier, idx, axis = 0)\n",
    "identifier = identifier[:, :3]\n",
    "\n",
    "\n",
    "'''\n",
    "Handling NaN Values by Trial\n",
    "'''\n",
    "def cubic_interp(trial):\n",
    "    interp_trial = np.empty(np.shape(trial))\n",
    "    for i in range(trial.shape[-2]):\n",
    "        for j in range(trial.shape[-1]):\n",
    "            df = pd.Series(trial[:, i, j])\n",
    "            interp_trial[:, i, j] = np.asarray(df.interpolate(method = 'cubic', limit = 299))\n",
    "    return interp_trial\n",
    "\n",
    "\n",
    "#separate NaN indices \n",
    "timesteps, ccords, n_trial, n_channel = np.where(np.isnan(y))\n",
    "removal = []\n",
    "for trial in set(n_trial):\n",
    "    if np.any(np.isnan(y[299, :, trial, :])):\n",
    "        removal.append(trial)\n",
    "    else:\n",
    "        y[:, :, trial, :] = cubic_interp(y[:, :, trial, :])\n",
    "        identifier[trial, 2] = True\n",
    "\n",
    "\n",
    "#Remove un-interpolatable trials from data\n",
    "X = np.delete(X, removal, axis = 1)\n",
    "y = np.delete(y, removal, axis = 2)\n",
    "identifier = np.delete(identifier, removal, axis = 0)\n",
    "\n",
    "\n",
    "'''\n",
    "Shape Validation\n",
    "'''\n",
    "#Validate shapes\n",
    "print(\"Data Shape: \", X.shape)\n",
    "print(\"Label Shape: \", y.shape)\n",
    "print(\"Identifier Shape: \", identifier.shape)\n",
    "assert X.shape[0] == 4564, \"X Shape Invalid: Should have 4564 timesteps\"\n",
    "assert X.shape[2] == 5, \"X Shape Invalid: Should have 5 Channels\"\n",
    "assert y.shape[0] == 300, \"y Shape Invalid: Should have 300 timesteps\"\n",
    "assert y.shape[1] == 3, \"y Shape Invalid: Each timestep should have 3 (cartesian) dimensions\"\n",
    "assert y.shape[3] == 7, \"y Shape Invalid: Should have 7 Channels\"\n",
    "assert X.shape[1] == y.shape[2] == identifier.shape[0], \"Shapes Invalid: The trial dimension of X, y, and identifier needs to match\"\n",
    "print(\"Shapes Validated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train-Val-Test Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 0.7\n",
    "val = 0.2\n",
    "test = 0.1\n",
    "np.random.seed(42) # for consistent train/val/test splits\n",
    "\n",
    "\n",
    "#Calculate useful numbers\n",
    "num_trials = identifier.shape[0]\n",
    "num_train = int(train*num_trials)\n",
    "num_val = int(val*num_trials)\n",
    "num_test = int(test*num_trials)\n",
    "\n",
    "\n",
    "#All possible trial indices\n",
    "available_idx = np.arange(num_trials)\n",
    "\n",
    "\n",
    "#Make sure interpolated labels do not affect ability to verify model performance\n",
    "idx = np.where(identifier[:,2] == 'True')[0]\n",
    "X_train = X[:, idx, :]\n",
    "y_train = y[:, :, idx, :]\n",
    "id_train = identifier[idx, :2]\n",
    "\n",
    "\n",
    "#Remove indices we should no longer access, then form indices\n",
    "available_idx = np.delete(available_idx, idx)\n",
    "np.random.shuffle(available_idx)\n",
    "train_idx = available_idx[:num_train-len(idx)]\n",
    "val_idx = available_idx[num_train-len(idx):num_train - len(idx) + num_val]\n",
    "test_idx = available_idx[num_train - len(idx) + num_val:]\n",
    "\n",
    "\n",
    "#combine interpolated training data with the rest of the training data\n",
    "X_train = np.hstack((X_train, X[:, train_idx, :]))\n",
    "y_train = np.dstack((y_train, y[:, :, train_idx, :]))\n",
    "id_train = np.vstack((id_train, identifier[train_idx, :2]))\n",
    "\n",
    "\n",
    "#Create validation data\n",
    "X_val = X[:, val_idx, :]\n",
    "y_val = y[:, :, val_idx, :]\n",
    "id_val = identifier[val_idx, :2]\n",
    "\n",
    "\n",
    "#Create test data\n",
    "X_test = X[:, test_idx, :]\n",
    "y_test = y[:, :, test_idx, :]\n",
    "id_test = identifier[test_idx, :2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
