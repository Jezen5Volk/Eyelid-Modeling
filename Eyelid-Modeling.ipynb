{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "mat = scipy.io.loadmat('eyeliddata.mat', simplify_cells = True)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Reorganization** <br>\n",
    "Reorganizing provided matlab file and interpolating over recoverable NaN labels\n",
    "\n",
    "For a single trial, \n",
    "\n",
    "- Marker kinematics are provided at 400 Hz, shape (300, 3) --> 0.75 s\n",
    "- EMG information is provided at 6103.5 Hz, shape (4564,) --> 0.7478 s\n",
    "\n",
    "Marker and EMG data are time-synced. Blinking starts at around 0.25 seconds, which corresponds to point 100 for the kinematics data and point 1525 in the EMG data\n",
    "\n",
    "Since only electrodes u1, u2, u3, u4, and t2 were used in common across all participants, our input to the model (without spectral preprocessing) will be of shape (4564, N, 5). Since only markerset x1, x2, A, B, C, D, E were used in common across all participants, our labels will be of shape (N, 7, 300, 3). In other words, $x \\in R^{T_{\\mathrm{in}}\\times N \\times C_{\\mathrm{in}}}$, where $T_{\\mathrm{in}}$ is the number of timesteps (4564, in this case), N is the batch size, and $C_{\\mathrm{in}}$ is the number of channels (5, in this case), while $y \\in R^{T_{\\mathrm{out}}\\times 3\\times N \\times C_{\\mathrm{out}}}$, where where $T_{\\mathrm{out}}$ is the number of timesteps (300 x 3, in this case), N is the batch size, and $C_{\\mathrm{out}}$ is the number of channels (7, in this case).\n",
    "\n",
    "To reorganize the data for train-test-val splits, the Nth data/label pair should contain the timeseries for emg electrodes u1, u2, u3, u4, t2/the timeseries for markerset x1, x2, A, B, C, D, E. In addition to this, a static identification label is generated which contains an identifying string combining the subject, blink type, and trial number (ie: 'sub1_spon#23'), a boolean hyperparameter indicating eye side (True = Right Eye, False = Left Eye); and a flag to identify whether the trial contains NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (4564, 986, 5)\n",
      "Label Shape:  (300, 3, 986, 7)\n",
      "Identifier Shape:  (986, 3)\n",
      "Shapes Validated!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Reorganize Data\n",
    "'''\n",
    "eye_bool = np.asarray([True, True, False, True, True, False, False, False])\n",
    "electrode_list = ['u1', 'u2', 'u3', 'u4', 't2']\n",
    "marker_list = ['x1', 'x2', 'u1', 'u2', 'u3', 'u4', 'u5']\n",
    "\n",
    "\n",
    "#Collect Data\n",
    "data = np.zeros((4564, 1, 5))\n",
    "for blink_key in mat['ForSamantha']['emg_with_notchfilter']:\n",
    "    for sub_key in mat['ForSamantha']['emg_with_notchfilter'][blink_key]:\n",
    "        trial = []\n",
    "        for electrode_key in electrode_list:\n",
    "            trial.append(mat['ForSamantha']['emg_with_notchfilter'][blink_key][sub_key][electrode_key])\n",
    "        trial = np.dstack(trial) #reshape to (4564, T, 5) where T is number of trials\n",
    "        data = np.hstack((data, trial)) #stack all trials along 1st axis --> (4564, N, 5)\n",
    "\n",
    "\n",
    "#Collect Label/Identifier\n",
    "identifier = []\n",
    "label = np.zeros((300, 3, 1, 7))\n",
    "for blink_key in mat['ForSamantha']['kinem']:\n",
    "    for sub_key in mat['ForSamantha']['kinem'][blink_key]:\n",
    "        trial = []\n",
    "        for marker_key in marker_list:\n",
    "            trial.append(mat['ForSamantha']['kinem'][blink_key][sub_key][marker_key])\n",
    "        trial = np.stack(trial, axis = -1) #reshape to (300, 3, T, 7) where T is number of trials\n",
    "\n",
    "        #Identifier markers for trials with incomplete data\n",
    "        throwaway = False\n",
    "        if trial.shape[0] != 300:\n",
    "            throwaway = True\n",
    "\n",
    "        #If not discarding a trial, stack it's label\n",
    "        if not(throwaway):\n",
    "            label = np.dstack((label, trial)) #stack all trials along 2nd axis --> (300, 3, N, 7)\n",
    "        \n",
    "        #Generate ID for each trial\n",
    "        for num in range(trial.shape[2]):\n",
    "            id_string = sub_key + '_' + blink_key + '#' + str(num + 1) \n",
    "            id_eye = eye_bool[int(sub_key.split('b')[1]) - 1]\n",
    "            identifier.append((id_string, id_eye, False, throwaway))\n",
    "\n",
    "\n",
    "#Remove placeholder\n",
    "X = data[:, 1:, :] \n",
    "y = label[:, :, 1:, :]\n",
    "identifier = np.asarray(identifier)\n",
    "\n",
    "\n",
    "#Remove throwaway trials from data/identifier\n",
    "idx = np.where(identifier[:,3] == 'True')\n",
    "X = np.delete(X, idx, axis = 1)\n",
    "identifier = np.delete(identifier, idx, axis = 0)\n",
    "identifier = identifier[:, :3]\n",
    "\n",
    "\n",
    "'''\n",
    "Handling NaN Values by Trial\n",
    "'''\n",
    "def cubic_interp(trial):\n",
    "    interp_trial = np.empty(np.shape(trial))\n",
    "    for i in range(trial.shape[-2]):\n",
    "        for j in range(trial.shape[-1]):\n",
    "            df = pd.Series(trial[:, i, j])\n",
    "            interp_trial[:, i, j] = np.asarray(df.interpolate(method = 'cubic', limit = 299))\n",
    "    return interp_trial\n",
    "\n",
    "\n",
    "#separate NaN indices \n",
    "timesteps, ccords, n_trial, n_channel = np.where(np.isnan(y))\n",
    "removal = []\n",
    "for trial in set(n_trial):\n",
    "    if np.any(np.isnan(y[299, :, trial, :])):\n",
    "        removal.append(trial)\n",
    "    else:\n",
    "        y[:, :, trial, :] = cubic_interp(y[:, :, trial, :])\n",
    "        identifier[trial, 2] = True\n",
    "\n",
    "\n",
    "#Remove un-interpolatable trials from data\n",
    "X = np.delete(X, removal, axis = 1)\n",
    "y = np.delete(y, removal, axis = 2)\n",
    "identifier = np.delete(identifier, removal, axis = 0)\n",
    "\n",
    "\n",
    "'''\n",
    "Flipping Z-Label for Right Eye (Ensuring Coordinate System Uniformity)\n",
    "'''\n",
    "for r_eye_idx in np.where(identifier[:,1] == 'True')[0]:\n",
    "    y[:, 2, r_eye_idx, :] = -1*y[:, 2, r_eye_idx, :]\n",
    "  \n",
    "\n",
    "'''\n",
    "Shape Validation\n",
    "'''\n",
    "#Validate shapes\n",
    "print(\"Data Shape: \", X.shape)\n",
    "print(\"Label Shape: \", y.shape)\n",
    "print(\"Identifier Shape: \", identifier.shape)\n",
    "assert X.shape[0] == 4564, \"X Shape Invalid: Should have 4564 timesteps\"\n",
    "assert X.shape[2] == 5, \"X Shape Invalid: Should have 5 Channels\"\n",
    "assert y.shape[0] == 300, \"y Shape Invalid: Should have 300 timesteps\"\n",
    "assert y.shape[1] == 3, \"y Shape Invalid: Each timestep should have 3 (cartesian) dimensions\"\n",
    "assert y.shape[3] == 7, \"y Shape Invalid: Should have 7 Channels\"\n",
    "assert X.shape[1] == y.shape[2] == identifier.shape[0], \"Shapes Invalid: The trial dimension of X, y, and identifier needs to match\"\n",
    "print(\"Shapes Validated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train-Val-Test Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 0.7\n",
    "val = 0.2\n",
    "test = 0.1\n",
    "np.random.seed(42) # for consistent train/val/test splits\n",
    "\n",
    "\n",
    "#Calculate useful numbers\n",
    "num_trials = identifier.shape[0]\n",
    "num_train = int(train*num_trials)\n",
    "num_val = int(val*num_trials)\n",
    "num_test = int(test*num_trials)\n",
    "\n",
    "\n",
    "#All possible trial indices\n",
    "available_idx = np.arange(num_trials)\n",
    "\n",
    "\n",
    "#Make sure interpolated labels do not affect ability to verify model performance\n",
    "idx = np.where(identifier[:,2] == 'True')[0]\n",
    "X_train = X[:, idx, :]\n",
    "y_train = y[:, :, idx, :]\n",
    "id_train = identifier[idx, :2]\n",
    "\n",
    "\n",
    "#Remove indices we should no longer access, then form indices\n",
    "available_idx = np.delete(available_idx, idx)\n",
    "np.random.shuffle(available_idx)\n",
    "train_idx = available_idx[:num_train-len(idx)]\n",
    "val_idx = available_idx[num_train-len(idx):num_train - len(idx) + num_val]\n",
    "test_idx = available_idx[num_train - len(idx) + num_val:]\n",
    "\n",
    "\n",
    "#combine interpolated training data with the rest of the training data\n",
    "X_train = torch.from_numpy(np.hstack((X_train, X[:, train_idx, :])))\n",
    "y_train = torch.from_numpy(np.dstack((y_train, y[:, :, train_idx, :])))\n",
    "id_train = np.vstack((id_train, identifier[train_idx, :2]))\n",
    "\n",
    "\n",
    "#Create validation data\n",
    "X_val = torch.from_numpy(X[:, val_idx, :])\n",
    "y_val = torch.from_numpy(y[:, :, val_idx, :])\n",
    "id_val = identifier[val_idx, :2]\n",
    "\n",
    "\n",
    "#Create test data\n",
    "X_test = torch.from_numpy(X[:, test_idx, :])\n",
    "y_test = torch.from_numpy(y[:, :, test_idx, :])\n",
    "id_test = identifier[test_idx, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models** <br>\n",
    "\n",
    "There are three different model architectures that I think would be important to explore for the purposes of this project: RNNs, LSTMs, and GRUs. In addition to these model architectures, it is worth pointing out that the data I have is not surface EMG data but data collected by needles inserted into the obicularis muscle. This means that there is finer resolution into picking up signals from individual motor units, which means that it is possible that there is enough information captured in the rectified EMG signal to recreate eyelid motions, without adding a pre-processing step to aquire the spectral form of the data. The ultimate goal is performance, which means that it is worth testing the model architectures with rectified EMG inputs vs spectral encoding, as well as if there is extra time, a combined model architecture which would accept spectral and rectified EMG. \n",
    "\n",
    "**Preprocessing**: Since the desired application is a real-time model of eyelid kinematics directly informed by the EMG behavior of the obicularis muscle, we need to break our data into windows. Thus, window length and window stride will end up being hyperparameters that we optimize for with Ray Tune, and for simplicity we'll use 'same' padding. This means that our input to the model will actually be of shape $X \\in R^{L \\times N_w \\times N_b \\times C}$ where $L$ is the length of our window, $N_w$ is the number of windows in a batch, $N_b$ is the number of examples in a batch, and $C$ is the number of channels present in the data (in this case, 5). Once the data is windowed, the next step in preprocessing is to either identify the frquency spectrum or to rectify the data. Finally, a 2d batchnorm step will be taken to set the input data to each channel to unit statistics. \n",
    "\n",
    "**Data Augmentation**: worry about that when ya get there, but timeseries jitter + SpecAugment\n",
    "\n",
    "**Model Architectures**: WORRY ABOUT THAT WHEN YA GET THERE\n",
    "\n",
    "**Training**: it's all downhill from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
